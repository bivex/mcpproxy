# Smart MCP Proxy â€” Design Document

## 1â€¯Overview

*Built on **FastMCP v2** for both its internal server runtime and as the client library to upstream MCP endpoints (ensuring dynamic tool registration and specâ€‘compliant notifications).*

The Smart MCP Proxy is a **federating gateway** that sits between an AI agent and any number of ModelÂ ContextÂ Protocol (MCP) servers. The proxy:

- **Discovers** tools exposed by upstream MCP servers (HTTP, SSE or stdio).
- **Indexes** their metadata using a configurable embedding backend (BM25, HuggingÂ Face local, or OpenAI).
- **Serves a single control tool `retrieve_tools`.** When the agent calls this tool, the proxy:
  1. Searches the index.
  2. **Automatically registers the topÂ 5 results** with its own FastMCP server instance.
  3. Emits `notifications/tools/list_changed` so connected clients immediately see the new tools, following MCP spec
- Persists tool metadata, SHAâ€‘256 hash and embedding reference in **SQLite +Â Faiss** for quick reload and change detection.

## 2â€¯Goals & Nonâ€‘Goals

|                                   | In Scope    | Out of Scope |
| --------------------------------- | ----------- | ------------ |
| Dynamic discovery of many MCP servers | âœ…           |              |
| Hybrid lexical / vector search        | âœ…           |              |
| Hotâ€‘reload of proxy without downtime  | ğŸš« (future) |              |
| Graphâ€‘based semantic reasoning        | ğŸš« (future) |              |

## 3â€¯Highâ€‘Level Architecture

```mermaid
graph TD
  subgraph Upstream MCP
    A1[company-mcp-server-http-prod]
A2[company-docs]
A3[company-mcp-server-with-oauth]
  end

  subgraph Proxy
    B1(ConfigÂ Loader) --> B2(IndexÂ Builder)
    B2 -->|vectors| B3(Faiss)
    B2 -->|metadata| B4(SQLite)
    B5(FastMCPÂ Server) -. list_changed .-> Agent
    B5 -- calls --> A1 & A2 & A3
  end

  Agent((AIÂ Agent))
  Agent -- retrieve_tool --> B5
  B5 -- new tool wrappers --> Agent
```

## 4â€¯Configuration

### 4.1â€¯Server list (Cursor IDEÂ style)

```json
{
  "mcpServers": {
    "company-mcp-server-http-prod":  {"url": "http://localhost:8081/mcp"},
"company-docs":                  {"url": "http://localhost:8000/sse"},
"company-mcp-server-with-oauth": {"url": "http://localhost:8080/mcp"},

"company-mcp-server-prod": {
  "command": "uvx",
  "args": [
    "--from", 
    "mcp-company-python@git+https://gitlab-ed7.cloud.gc.onl/algis.dumbris/mcp-company.git",
    "company-mcp-server"
  ],
  "env": {
    "COMPANY_TOKEN": "${COMPANY_TOKEN}",
        "PORT": "9090"
      }
    }
  }
}
```

### 4.2â€¯Embedding backend viaÂ ENV

| Variable         | Allowed values                                | Default |
| ---------------- | --------------------------------------------- | ------- |
| `SP_EMBEDDER`    | `BM25`, `HF`, `OPENAI`                        | `BM25`  |
| `SP_HF_MODEL`    | e.g. `sentence-transformers/all-MiniLM-L6-v2` | â€”       |
| `SP_TOOLS_LIMIT` | Integer (1-100)                               | `15`    |
| `OPENAI_API_KEY` | your key                                      | â€”       |

The proxy chooses the search driver at startup; mixedâ€‘mode hybrid search (lexical + vector) is possible in future.

### 4.3 Tool Pool Management

The proxy maintains an active pool of registered tools limited by `SP_TOOLS_LIMIT`. When the limit is exceeded, tools are evicted based on a weighted score:

```
weighted_score = (search_score * 0.7) + (freshness_score * 0.3)
freshness_score = 1.0 - min(1.0, age_in_seconds / 1800)  # 30min max age
```

This ensures:
- High-scoring tools are prioritized
- Recently accessed tools stay fresh
- Older, lower-scoring tools are evicted first

## 5â€¯SQLiteÂ +Â Faiss Schema

```sql
-- SQLite (file: proxy.db)
CREATE TABLE tools (
  id              INTEGER PRIMARY KEY,
  name            TEXT NOT NULL,
  description     TEXT,
  hash            TEXT NOT NULL,
  server_name     TEXT NOT NULL,
  faiss_vector_id INTEGER UNIQUE
);
CREATE INDEX idx_tools_hash ON tools(hash);
```

- **Vectors** are stored in a sideâ€‘car Faiss index (`tools.faiss`). `faiss_vector_id` provides the linkage.
- SHAâ€‘256Â hash =Â `sha256(name||description||params_json)` enables change detection.

## 6â€¯OperationalÂ Flow

| Phase            | Action                                                                                                                        |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------- |
| **Startâ€‘up**     | 1ï¸âƒ£Â Load JSON config â†’ 2ï¸âƒ£Â Fetch `tools/list` from each server â†’ 3ï¸âƒ£Â Insert/Update SQLite rows, embed & upsert Faiss vectors. |
| **User query**   | 4ï¸âƒ£Â Agent calls `retrieve_tool(query)` â†’ 5ï¸âƒ£Â Proxy scores candidates, enforces pool limit, registers wrappers, fires `list_changed`.  |
| **Invocation**   | 6ï¸âƒ£Â Agent invokes newly appeared tools as normal MCP calls.                                                                   |
| **Refresh loop** | 7ï¸âƒ£Â Proxy polls upstream `notifications/tools/list_changed` (or periodic list) to maintain single source of truth.            |

## 7â€¯SecurityÂ &Â Rateâ€‘Limiting

- **OAuth**: servers marked with `oauth=true` in extended config use bearer tokens cached in memory.
- **Perâ€‘origin quotas**: simple tokenâ€‘bucket keyed by `server_name`.
- **Sandbox**: new wrappers execute via FastMCP's remote client; no Python eval happens inside the proxy.

## 8â€¯AlternativeÂ Designs

| Option                    | Pros                             | Cons                                    |
| ------------------------- | -------------------------------- | --------------------------------------- |
| **Remote pgvector DB**    | Horizontal scale, SQL queries    | Adds external dependency                |
| **Graph RAG (KG + HNSW)** | Captures interâ€‘tool dependencies | Higher complexity / writeâ€‘amplification |

## 9â€¯OpenÂ Questions

1. How much weight should synthetic questions (Ã  la TDWA in ScaleMCP) have in embeddings vs. plain BM25?  
2. Should topâ€‘k be adaptive (e.g., score â‰¥ 0.8) instead of a fixed 5?  
3. Would batching multiple `retrieve_tools` calls per user request, as ScaleMCP does, significantly improve latency?  
